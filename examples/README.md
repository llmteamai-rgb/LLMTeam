# llmteam Examples

This directory contains examples for using `llmteam` in various scenarios.

- **[Quickstart](quickstart/)**: Run your first workflow in 5 minutes.
- **[LLM Chat](llm_chat/)**: Build a chat workflow with memory.
- **[Conditional Flow](conditional_flow/)**: Branching logic and conditions.
- **[Parallel Processing](parallel_processing/)**: Execute steps in parallel.
- **[Loops & Errors](loops_and_errors/)**: Iteration and retry mechanisms.
- **[FastAPI Server](fastapi_server/)**: Serve workflows via HTTP API.
- **[Enterprise](enterprise/)**: Multi-tenancy, secrets, and OIDC.
- **[Custom Handler](custom_handler/)**: Extend llmteam with your own logic.
